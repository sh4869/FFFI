<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<style>
    canvas {
        border: 1px solid black;
    }

    .invisible {
        display: none;
    }

    .text-center {
        text-align: center;
    }

    .center-block {
        display: block;
        margin: auto;
    }

    .row {
        margin: 10px;
    }

    tr td {
        padding-right: 10px;
        width: 25%;
        vertical-align: top;
        font: 14px 'Lucida Grande', sans-serif;
    }

</style>
<body>
    <div id="container">
        <div class="invisible">
            <video id="video" class="hidden">Your browser does not support the video tag.</video>
        </div>
        <canvas class="center-block" id="canvasOutput" width=320 height=240></canvas>
        <p class="fps"></p>
    </div>
</body>
<script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
<script src="https://threejs.org/examples/js/libs/stats.min.js"></script>
<script>
    var Module = {
        wasmBinaryFile: 'https://huningxin.github.io/opencv.js/build/wasm/opencv_js.wasm',
        _main: function () { opencvIsReady(); }
    };
</script>
<script async src="https://huningxin.github.io/opencv.js/build/wasm/opencv.js"></script>

<script>
    // In this case, We set width 320, and the height will be computed based on the input stream.
    let width = 320;
    let height = 0;

    // whether streaming video from the camera.
    let streaming = false;

    let video = document.getElementById("video");
    let stream = null;
    let vc = null;

    let src = null;
    let dst = null;
    let dst2 = null;
    var stats = null;
    var audioCtx = null;
    let firstTime = null;
    let lastMoment = { x: 0, y: 0 };
    let centerCount = 0;
    let update = false;
    let updateCount = 0;
    var oscillator;
    var oscillator2;
    var oscillator3;

    function startCamera() {
        if (streaming) return;
        navigator.mediaDevices.getUserMedia({ video: true, audio: true })
            .then(function (s) {
                stream = s;
                video.srcObject = s;
                video.play();
                oscillator = audioCtx.createOscillator();
                oscillator.type = 'square';
                oscillator.frequency.value = 440;
                oscillator.detune.value = 100;
                oscillator.connect(audioCtx.destination);
                oscillator.start(0);
            })
            .catch(function (err) {
                console.log("An error occured! " + err);
            });

        video.addEventListener("canplay", function (ev) {
            if (!streaming) {
                height = video.videoHeight / (video.videoWidth / width);
                video.setAttribute("width", width);
                video.setAttribute("height", height);
                streaming = true;
                vc = new cv.VideoCapture(video);
            }
            startVideoProcessing();
        }, false);
    }

    function startVideoProcessing() {
        if (!streaming) { console.warn("Please startup your webcam"); return; }
        stopVideoProcessing();
        src = new cv.Mat(height, width, cv.CV_8UC4);
        dst = new cv.Mat(height, width, cv.CV_8UC3);
        dst2 = new cv.Mat(height, width, cv.CV_8UC1);

        requestAnimationFrame(processVideo);
    }

    // 重心を取得
    function getMomemnt(src) {
        cv.cvtColor(src, dst, cv.COLOR_RGB2HSV);
        let lowScalar = new cv.Scalar(70, 100, 30);
        let highScalar = new cv.Scalar(120, 255, 200);
        let low = new cv.Mat(height, width, dst.type(), lowScalar);
        let high = new cv.Mat(height, width, dst.type(), highScalar);
        cv.inRange(dst, low, high, dst2)
        let mu = cv.moments(dst2);
        return { x: mu.m10 / mu.m00, y: mu.m01 / mu.m00 };
    }

    function aveHeltz() {
        let sum = 0;
        for (let i = 0; i < 5; i++) {
            sum += heltzs[i];
        }
        return sum / 5;
    }

    function processVideo() {
        stats.begin();
        if (firstTime === null) {
            firstTime = Date.now();
        }
        vc.read(src);
        const moment = getMomemnt(src);
        
        if ((lastMoment.x > src.cols / 2 && moment.x <= src.cols / 2)  || (lastMoment.x < src.cols / 2 && moment.x >= src.cols / 2)) {
            updateCount++;
            console.log("update!");
            if (updateCount > 1) {
                update = true;
                updateCount = 0;
            }
        }
        cv.imshow("canvasOutput", src);
        stats.end();
        if (update) {
            const heltz = 1000 / (Date.now() - firstTime) * 120;
            const result = 440 * Math.pow(2, Math.floor(Math.log2(heltz / 440) * 12) / 12);
            oscillator.frequency.value = result;
            console.log(result)
            document.querySelector(".fps").innerText = result.toString() + "fps";
            firstTime = null;
            update = false;
        }
        lastMoment = moment;
        requestAnimationFrame(processVideo);
    }

    function stopVideoProcessing() {
        if (src != null && !src.isDeleted()) src.delete();
        if (dst != null && !dst.isDeleted()) dst.delete();
        if (dst2 != null && !dst2.isDeleted()) dst2.delete();
    }


    function opencvIsReady() {
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        console.log('OpenCV.js is ready');
        stats = new Stats();
        startCamera();
    }
</script>
