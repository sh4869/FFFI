<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" />
<style>
    canvas {
        border: 1px solid black;
    }

    .invisible {
        display: none;
    }

    .text-center {
        text-align: center;
    }

    .center-block {
        display: block;
        margin: auto;
    }

    .row {
        margin: 10px;
    }

    tr td {
        padding-right: 10px;
        width: 25%;
        vertical-align: top;
        font: 14px "Lucida Grande", sans-serif;
    }
</style>
<body>
    <div id="container">
        <div class="invisible"><video id="video" class="hidden">Your browser does not support the video tag.</video></div>
        <canvas class="center-block" id="canvasOutput" width="320" height="240"></canvas>
        <p>Speed: <span class="speed"></span></p>
        <p>Hz: <span class="heltz"></span></p>
    </div>
</body>
<script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
<script src="https://threejs.org/examples/js/libs/stats.min.js"></script>
<script>
    var Module = {
        wasmBinaryFile: "https://huningxin.github.io/opencv.js/build/wasm/opencv_js.wasm",
        _main: function() {
            opencvIsReady();
        }
    };
</script>
<script async src="https://huningxin.github.io/opencv.js/build/wasm/opencv.js"></script>

<script>
    // In this case, We set width 320, and the height will be computed based on the input stream.
    let width = 960;
    let height = 0;

    // whether streaming video from the camera.
    let streaming = false;

    let video = document.getElementById("video");
    let stream = null;
    let vc = null;

    let src = null;
    let dst = null;
    let dst2 = null;
    var stats = null;
    var audioCtx = null;
    let firstTime = null;
    let lastMoment = { x: 0, y: 0 };
    let centerCount = 0;
    let update = false;
    let updateCount = 0;
    var oscillator;
    var oscillator2;
    var oscillator3;

    function startCamera() {
        if (streaming) return;
        navigator.mediaDevices
            .getUserMedia({ video: true, audio: true })
            .then(function(s) {
                stream = s;
                video.srcObject = s;
                video.play();
                oscillator = audioCtx.createOscillator();
                oscillator.type = "square";
                oscillator.frequency.value = 440;
                oscillator.detune.value = 0;
                oscillator.connect(audioCtx.destination);
                oscillator.start(0);
            })
            .catch(function(err) {
                console.log("An error occured! " + err);
            });

        video.addEventListener(
            "canplay",
            function(ev) {
                if (!streaming) {
                    height = video.videoHeight / (video.videoWidth / width);
                    video.setAttribute("width", width);
                    video.setAttribute("height", height);
                    streaming = true;
                    vc = new cv.VideoCapture(video);
                }
                startVideoProcessing();
            },
            false
        );
    }

    function startVideoProcessing() {
        if (!streaming) {
            console.warn("Please startup your webcam");
            return;
        }
        stopVideoProcessing();
        src = new cv.Mat(height, width, cv.CV_8UC4);
        dst = new cv.Mat(height, width, cv.CV_8UC3);
        dst2 = new cv.Mat(height, width, cv.CV_8UC1);

        requestAnimationFrame(processVideo);
    }

    // 重心を取得
    function getMomemnt(src) {
        cv.cvtColor(src, dst, cv.COLOR_RGB2HSV);
        let lowScalar = new cv.Scalar(70, 100, 30);
        let highScalar = new cv.Scalar(120, 255, 200);
        let low = new cv.Mat(height, width, dst.type(), lowScalar);
        let high = new cv.Mat(height, width, dst.type(), highScalar);
        cv.inRange(dst, low, high, dst2);
        let mu = cv.moments(dst2);
        return { x: mu.m10 / mu.m00, y: mu.m01 / mu.m00 };
    }

    const distancesSize = 30;
    let distances = Array(distancesSize).fill(0);
    function processVideo() {
        stats.begin();
        vc.read(src);
        const moment = getMomemnt(src);
        cv.circle(src, moment, 2, [255, 0, 0, 255]);
        cv.line(src, lastMoment, moment, [255, 0, 0, 255]);
        cv.imshow("canvasOutput", src);
        stats.end();

        const distance = Math.sqrt((moment.x - lastMoment.x) ** 2 + (moment.y - lastMoment.y) ** 2)/3;
        if (!isNaN(distance) && !(moment.x == 0 && moment.y == 0)) {
            distances.push(distance);
            distances.shift();
        }
        const totalDistance = distances.reduce((accumlator, currentValue) => accumlator + currentValue);
        const speed = totalDistance / distances.length;
        const heltz = speed * 20 + 100; //speedが0-30の範囲で200Hz-500Hzぐらいになるように調整

        oscillator.frequency.value = heltz;
        document.querySelector(".speed").innerText = speed.toString();
        document.querySelector(".heltz").innerText = heltz;

        lastMoment = moment;
        requestAnimationFrame(processVideo);
    }

    function stopVideoProcessing() {
        if (src != null && !src.isDeleted()) src.delete();
        if (dst != null && !dst.isDeleted()) dst.delete();
        if (dst2 != null && !dst2.isDeleted()) dst2.delete();
    }

    function opencvIsReady() {
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        console.log("OpenCV.js is ready");
        stats = new Stats();
        startCamera();
    }
</script>
